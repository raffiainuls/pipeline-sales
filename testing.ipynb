{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-36.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\python312\\lib\\site-packages (from faker) (2024.1)\n",
      "Downloading Faker-36.1.1-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 508.0 kB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 633.2 kB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 633.2 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/1.9 MB 653.7 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/1.9 MB 653.7 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.0/1.9 MB 653.7 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.3/1.9 MB 583.5 kB/s eta 0:00:02\n",
      "   --------------------------- ------------ 1.3/1.9 MB 583.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 1.6/1.9 MB 586.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 675.0 kB/s eta 0:00:00\n",
      "Installing collected packages: faker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\faker.exe' -> 'C:\\\\Python312\\\\Scripts\\\\faker.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy data berhasil dibuat dan disimpan sebagai dummy_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "from faker import Faker \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# generate tbl_branch\n",
    "# Inisialisasi Faker \n",
    "fake = Faker()\n",
    "# Jumlah data \n",
    "num_records = 50 \n",
    "# dummy data \n",
    "branch_data ={\n",
    "    \"id\":[i + 1 for i in range(num_records)],\n",
    "    \"name\":[fake.company() for _ in range(num_records)],\n",
    "    \"location\":[fake.city() for _ in range(num_records)],\n",
    "    \"address\":[fake.address() for _ in range(num_records)],\n",
    "    \"email\":[fake.email() for _ in range(num_records)],\n",
    "    \"phone\":[fake.phone_number() for _ in range(num_records)],\n",
    "    \"created_time\":[fake.date_time_this_decade() for _ in range(num_records)],\n",
    "    \"modified_time\":[fake.date_time_this_decade() for _ in range(num_records)]\n",
    "}\n",
    "df_branch = pd.DataFrame(branch_data)\n",
    "\n",
    "\n",
    "# generate tbl_employee\n",
    "employee_data = []\n",
    "# working_hours = [(7,15), (10,18), (14,22)]\n",
    "global_employee_id = 1\n",
    "\n",
    "for branch_id in branch_data[\"id\"]:\n",
    "    employee_list = []\n",
    "    total_employees = random.randint(5,10)\n",
    "    active_count = 0 \n",
    "\n",
    "    for  _ in range(total_employees):\n",
    "        created_at = fake.date_time_this_decade()\n",
    "        modified_at = created_at + timedelta(days=random.randint(0,30))\n",
    "\n",
    "        # Pastikan minimal 3 karyawan aktif\n",
    "        if active_count < 3:\n",
    "            active_status = True\n",
    "            active_count +=1\n",
    "        else:\n",
    "            active_status = random.choice([True, False])\n",
    "            if active_status:\n",
    "                active_count += 1\n",
    "        \n",
    "        employee_list.append({\n",
    "                \"id\": global_employee_id,\n",
    "                \"branch_id\": branch_id,\n",
    "                \"name\": fake.name(),\n",
    "                \"salary\": round(random.uniform(3000000, 8000000),2),\n",
    "                \"active\": active_status,\n",
    "                \"address\": fake.address(),\n",
    "                \"phone\": fake.phone_number(),\n",
    "                \"email\": fake.email(),\n",
    "                \"created_at\": fake.date_time_this_decade(),\n",
    "            })\n",
    "        \n",
    "        global_employee_id += 1\n",
    "\n",
    "    employee_data.extend(employee_list)\n",
    "\n",
    "df_employee = pd.DataFrame(employee_data)\n",
    "\n",
    "\n",
    "\n",
    "# generate tbl schedulle\n",
    "# function for get day from date \n",
    "def get_day_of_week(date):\n",
    "    return date.strftime('%A') # get name from date\n",
    "\n",
    "# define shift \n",
    "#shifts = [(7,12), (12,17), (17,22)]\n",
    "\n",
    "schedule_data = []\n",
    "global_schedule_id = 1\n",
    "\n",
    "start_date = datetime(datetime.now().year, 1,1)\n",
    "end_date = datetime(datetime.now().year,12,31)\n",
    "delta = end_date - start_date\n",
    "\n",
    "\n",
    "for branch_id in branch_data[\"id\"]:\n",
    "    active_employees = [emp for emp in employee_data if emp[\"branch_id\"] == branch_id and emp[\"active\"]]\n",
    "    if len(active_employees)< 3:\n",
    "        continue # skip branch if active_employees kurang dari 3\n",
    "\n",
    "    for day in range(delta.days + 1):\n",
    "        current_date = start_date + timedelta(days= day)\n",
    "\n",
    "        # get day from date \n",
    "        day_of_week = get_day_of_week(current_date)\n",
    "\n",
    "        # define jumlah jaga based on weekday or weekend \n",
    "        if day_of_week in [\"Saturday\", \"Sunday\"]: \n",
    "            num_employees = min(2, len(active_employees))\n",
    "            shifts = [(10,15), (15,20)]\n",
    "            shifts = [(7,12), (12,17), (17,22)]\n",
    "        else:\n",
    "            num_employees = len(active_employees)\n",
    "            shifts = [(7,12), (12,17), (17,22)]\n",
    "\n",
    "        # distribusi shift karyawan \n",
    "        shift_capacities = [num_employees // len(shifts)] * len(shifts)\n",
    "        for i in range(num_employees % len(shifts)):\n",
    "            shift_capacities[i] +=1 # tambahkan sisa karyawan ke shift pertama    \n",
    "\n",
    "        employees_left = active_employees[:]\n",
    "        shift_assignments = []\n",
    "\n",
    "        for i, (shift_start, shift_end)  in enumerate(shifts):\n",
    "            if shift_capacities[i] > 0:\n",
    "                assigned_employees = random.sample(employees_left, shift_capacities[i]) # get random employee for shift\n",
    "                shift_assignments.append((assigned_employees, f\"{shift_start}:00 - {shift_end}:00\"))\n",
    "                employees_left = [emp for emp in employees_left if emp not in assigned_employees] # delete assign employee from list employee\n",
    "\n",
    "        for assigned_employees, shift_time in shift_assignments:\n",
    "            for emp in assigned_employees:\n",
    "                schedule_data.append({\n",
    "                    \"id\": global_schedule_id,\n",
    "                    \"branch_id\": branch_id,\n",
    "                    \"employee_id\": emp[\"id\"],\n",
    "                    \"day\": day_of_week,\n",
    "                    \"date\": current_date.date(),\n",
    "                    \"jam_shift\": shift_time,\n",
    "                    \"created_time\": fake.date_time_this_decade(),\n",
    "                })\n",
    "                global_schedule_id +=1\n",
    "\n",
    "df_schedule = pd.DataFrame(schedule_data)\n",
    "\n",
    "\n",
    "    \n",
    "with pd.ExcelWriter(\"dummy_data3.xlsx\") as writer:\n",
    "    df_branch.to_excel(writer, sheet_name=\"Branch\", index=False)\n",
    "    df_employee.to_excel(writer, sheet_name=\"Employee\", index=False)\n",
    "    df_schedule.to_excel(writer, sheet_name=\"Schedule\", index=False)\n",
    "\n",
    "print(\"Dummy data berhasil dibuat dan disimpan sebagai dummy_data.xlsx\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>day</th>\n",
       "      <th>date</th>\n",
       "      <th>jam_shift</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>7:00 - 12:00</td>\n",
       "      <td>2023-04-17 09:52:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>12:00 - 17:00</td>\n",
       "      <td>2022-08-18 08:48:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>17:00 - 22:00</td>\n",
       "      <td>2024-03-15 11:07:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>7:00 - 12:00</td>\n",
       "      <td>2020-10-20 17:05:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>12:00 - 17:00</td>\n",
       "      <td>2025-01-03 01:49:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75123</th>\n",
       "      <td>75124</td>\n",
       "      <td>50</td>\n",
       "      <td>347</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>7:00 - 12:00</td>\n",
       "      <td>2020-10-30 16:40:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75124</th>\n",
       "      <td>75125</td>\n",
       "      <td>50</td>\n",
       "      <td>348</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>12:00 - 17:00</td>\n",
       "      <td>2020-06-14 16:31:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75125</th>\n",
       "      <td>75126</td>\n",
       "      <td>50</td>\n",
       "      <td>341</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>12:00 - 17:00</td>\n",
       "      <td>2024-05-28 04:19:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75126</th>\n",
       "      <td>75127</td>\n",
       "      <td>50</td>\n",
       "      <td>343</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>17:00 - 22:00</td>\n",
       "      <td>2022-12-18 13:04:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75127</th>\n",
       "      <td>75128</td>\n",
       "      <td>50</td>\n",
       "      <td>349</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>17:00 - 22:00</td>\n",
       "      <td>2021-02-12 14:37:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75128 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  branch_id  employee_id        day        date      jam_shift  \\\n",
       "0          1          1            1  Wednesday  2025-01-01   7:00 - 12:00   \n",
       "1          2          1            3  Wednesday  2025-01-01  12:00 - 17:00   \n",
       "2          3          1            2  Wednesday  2025-01-01  17:00 - 22:00   \n",
       "3          4          1            2   Thursday  2025-01-02   7:00 - 12:00   \n",
       "4          5          1            3   Thursday  2025-01-02  12:00 - 17:00   \n",
       "...      ...        ...          ...        ...         ...            ...   \n",
       "75123  75124         50          347  Wednesday  2025-12-31   7:00 - 12:00   \n",
       "75124  75125         50          348  Wednesday  2025-12-31  12:00 - 17:00   \n",
       "75125  75126         50          341  Wednesday  2025-12-31  12:00 - 17:00   \n",
       "75126  75127         50          343  Wednesday  2025-12-31  17:00 - 22:00   \n",
       "75127  75128         50          349  Wednesday  2025-12-31  17:00 - 22:00   \n",
       "\n",
       "             created_time  \n",
       "0     2023-04-17 09:52:23  \n",
       "1     2022-08-18 08:48:39  \n",
       "2     2024-03-15 11:07:41  \n",
       "3     2020-10-20 17:05:09  \n",
       "4     2025-01-03 01:49:43  \n",
       "...                   ...  \n",
       "75123 2020-10-30 16:40:58  \n",
       "75124 2020-06-14 16:31:05  \n",
       "75125 2024-05-28 04:19:16  \n",
       "75126 2022-12-18 13:04:38  \n",
       "75127 2021-02-12 14:37:36  \n",
       "\n",
       "[75128 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime \n",
    "\n",
    "# product data \n",
    "\n",
    "data_product = [\n",
    "    (1, \"iPhone 15 Pro\", \"Electronics\", \"Smartphones\", 15000000, 5, 10),\n",
    "    (2, \"Samsung Galaxy S23\", \"Electronics\", \"Smartphones\", 20000000, 5, 5),\n",
    "    (3, \"MacBook Pro M3\", \"Electronics\", \"Laptops\", 22000000, 5, 20),\n",
    "    (4, \"Asus Zenbook Flip\", \"Electronics\", \"Laptops\", 11000000, 5, 20),\n",
    "    (5, \"Asus ROG Zephyrus G14\", \"Electronics\", \"Laptops\", 15000000, 5, 30),\n",
    "    (6, \"JBL Flip 6\", \"Electronics\", \"Speakers\", 3000000, 10, 100),\n",
    "    (7, \"Logitech MX Master 3\", \"Electronics\", \"Accessories\", 1700000, 20, 200),\n",
    "    (8, \"Air Jordan 1 Retro High Dior\", \"Apparel\", \"Footwear\", 125000000, 2, 5),\n",
    "    (9, \"Adidas Ultraboost\", \"Apparel\", \"Footwear\", 3000000, 10, 20),\n",
    "    (10, \"versace chain contour\", \"Apparel\", \"Clothing\", 2700000, 10, 20),\n",
    "    (11, \"Rolex Submariner\", \"Fashion\", \"Watches\", 150000000, 2, 5),\n",
    "    (12, \"Fossil Leather Wallet\", \"Fashion\", \"Accessories\", 1000000, 5, 10),\n",
    "    (13, \"Samsung 65\\\" Smart TV\", \"Home Appliances\", \"Televisions\", 10000000, 5, 40),\n",
    "    (14, \"Dyson V15 Vacuum\", \"Home Appliances\", \"Cleaning Devices\", 2000000, 10, 200),\n",
    "    (15, \"Philips Air Fryer\", \"Home Appliances\", \"Kitchen Appliances\", 700000, 10, 200),\n",
    "]\n",
    "\n",
    "created_time = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "df_product = pd.DataFrame(data_product, columns=[\"id\", \"product_name\", \"category\", \"sub_category\", \"price\", \"profit\", \"stock\"])\n",
    "df_product[\"created_time\"] = created_time\n",
    "\n",
    "df_product[\"modified_time\"] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "special_events = {\n",
    "    \"2025-01-01\": \"New Year\",\n",
    "    \"2025-02-10\": \"Chinese New Year\",\n",
    "    \"2025-02-14\": \"Valentine's Day\",\n",
    "    \"2025-03-08\": \"International Women's Day\",\n",
    "    \"2025-03-11\": \"Nyepi Day\",\n",
    "    \"2025-03-17\": \"St. Patrick's Day\",\n",
    "    \"2025-03-29\": \"Good Friday\",\n",
    "    \"2025-04-01\": \"April Fool's Day\",\n",
    "    \"2025-04-10\": \"Eid al-Fitr\",\n",
    "    \"2025-04-11\": \"Eid al-Fitr Holiday\",\n",
    "    \"2025-04-21\": \"Kartini Day\",\n",
    "    \"2025-05-01\": \"Labor Day\",\n",
    "    \"2025-05-09\": \"Ascension Day of Jesus Christ\",\n",
    "    \"2025-06-01\": \"Pancasila Day\",\n",
    "    \"2025-06-17\": \"Eid al-Adha\",\n",
    "    \"2025-07-04\": \"US Independence Day\",\n",
    "    \"2025-07-07\": \"Islamic New Year\",\n",
    "    \"2025-08-17\": \"Independence Day\",\n",
    "    \"2025-09-16\": \"Prophet Muhammad’s Birthday\",\n",
    "    \"2025-10-31\": \"Halloween\",\n",
    "    \"2025-11-10\": \"Heroes Day\",\n",
    "    \"2025-11-29\": \"Black Friday\",\n",
    "    \"2025-12-24\": \"Christmas Eve\",\n",
    "    \"2025-12-25\": \"Christmas Day\",\n",
    "    \"2025-12-26\": \"Boxing Day\",\n",
    "    \"2025-12-31\": \"New Year's Eve\"\n",
    "}\n",
    "\n",
    "current_year = datetime.now().year\n",
    "# add event setiap akhir bulan \n",
    "for month in range(1,13):\n",
    "    last_day = datetime(current_year, month, 1) + timedelta(days=32)\n",
    "    last_day = last_day.replace(day=1) - timedelta(days=1)\n",
    "    special_events[last_day.strftime(\"%Y-%m-%d\")] = f\"End of {last_day.strftime('%B')} Sale\"\n",
    "\n",
    "promotion_data = []\n",
    "promo_id = 1 \n",
    "\n",
    "for date, event in sorted(special_events.items()):\n",
    "    promotion_data.append({\n",
    "        \"id\": promo_id,\n",
    "        \"event_name\": f\"{event} ({date})\",\n",
    "        \"disc\": random.randint(5,10),\n",
    "        \"time\": date,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    })\n",
    "    promo_id +=1\n",
    "\n",
    "df_promotions = pd.DataFrame(promotion_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "import faker \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = faker.Faker()\n",
    "\n",
    "num_records_cust = 100\n",
    "\n",
    "data_cust = []\n",
    "for i in range(1, num_records_cust + 1):\n",
    "    name = fake.name()\n",
    "    address = fake.address().replace(\"\\n\", \", \")\n",
    "    phone = fake.phone_number()\n",
    "    email = fake.email()\n",
    "    created_at = fake.date_time_between(start_date=\"-2y\", end_date=\"now\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    modified_at = (datetime.strptime(created_at, \"%Y-%m-%d %H:%M:%S\") + timedelta(days=random.randint(1, 365))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    data_cust.append([i, name, address, phone, email, created_at, modified_at])\n",
    "\n",
    "df_cust = pd.DataFrame(data_cust, columns=[\"id\", \"name\", \"address\", \"phone\", \"email\", \"created_at\", \"modified_at\",])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "data_payment_method = {\n",
    "    (1, \"Cash Payment\"),\n",
    "    (2, \"Bank Transfer\"),\n",
    "    (3, \"Credit Card\"),\n",
    "    (4, \"Virtual Account\")\n",
    "}\n",
    "data_order_status = {\n",
    "    (1, \"ongoing\"),\n",
    "    (2, \"done\")\n",
    "}\n",
    "data_payment_status = {\n",
    "    (1, \"processing\"),\n",
    "    (2, \"paid\"),\n",
    "    (3, \"failed\")\n",
    "}\n",
    "data_shipping_status = {\n",
    "    (1, \"ongoing\"),\n",
    "    (2, \"done\"),\n",
    "    (3, \"failed\")\n",
    "}\n",
    "\n",
    "\n",
    "created_time = datetime.today().strftime('%Y-%m-%d')\n",
    "df_payment_method = pd.DataFrame(data_payment_method, columns = [\"id\", \"name\"])\n",
    "df_order_status = pd.DataFrame(data_order_status, columns=[\"id\", \"name\"])\n",
    "df_payment_status = pd.DataFrame(data_payment_status, columns=[\"id\", \"name\"])\n",
    "df_shipping_status = pd.DataFrame(data_shipping_status, columns=[\"id\", \"name\"])\n",
    "\n",
    "df_payment_method[\"created_time\"] = created_time\n",
    "df_order_status[\"created_time\"] = created_time\n",
    "df_payment_status[\"created_time\"] = created_time\n",
    "df_shipping_status[\"created_time\"] = created_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "import faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = faker.Faker()\n",
    "customer_ids = df_cust[\"id\"].tolist()\n",
    "product_ids = df_product[\"id\"].tolist()\n",
    "branch_ids = df_branch[\"id\"].tolist()\n",
    "\n",
    "transactions_per_month = random.randint(500, 1000)\n",
    "\n",
    "order_status_options = [1, 2]\n",
    "order_status_weghts = [0.1, 0.9]\n",
    "\n",
    "payment_status_options = [1, 2, 3]\n",
    "payment_status_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "payment_method_options = [1, 2, 3, 4]\n",
    "\n",
    "shipping_status_options = [1, 2, 3]\n",
    "shipping_status_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "sales_data = []\n",
    "sale_id = 1\n",
    "\n",
    "def get_random_order_time(date):\n",
    "    if date.weekday() < 5:  # Weekday (Monday-Friday)\n",
    "        hour = random.randint(7, 22)\n",
    "    else:  # Weekend (Saturday-Sunday)\n",
    "        hour = random.randint(10, 20)\n",
    "    minute = random.randint(0, 59)\n",
    "    second = random.randint(0, 59)\n",
    "    return datetime(date.year, date.month, date.day, hour, minute, second)\n",
    "\n",
    "for month in range(1, 13):\n",
    "    start_date = datetime(2025, month, 1)\n",
    "    end_date = (start_date + timedelta(days=32)).replace(day=1) - timedelta(days=1)\n",
    "\n",
    "    for _ in range(transactions_per_month):\n",
    "        product_id = random.choice(product_ids)\n",
    "        customer_id = random.choice(customer_ids)\n",
    "        branch_id = random.choice(branch_ids)\n",
    "        quantity = random.randint(1,10)\n",
    "        payment_method = random.choice(payment_method_options)\n",
    "        is_online_transaction = random.choice([True, False])\n",
    "        delivery_fee = 0\n",
    "        is_free_delivery_fee = None \n",
    "\n",
    "        if is_online_transaction: \n",
    "            delivery_fee = random.randint(12000, 50000)\n",
    "            is_free_delivery_fee = random.choice([True, False])\n",
    "\n",
    "        random_date = fake.date_between(start_date=start_date, end_date=end_date)\n",
    "        order_date = get_random_order_time(random_date).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        order_status = random.choices(order_status_options, weights=order_status_weghts, k=1)[0]\n",
    "        payment_status = None\n",
    "        shipping_status = None\n",
    "\n",
    "        if order_status == 2:\n",
    "            payment_status = random.choices(payment_status_options, weights=payment_status_weights, k=1)[0]\n",
    "            if payment_status == 2:\n",
    "                shipping_status = random.choices(shipping_status_options, weights=shipping_status_weights, k=1)[0]\n",
    "       \n",
    "        if not is_online_transaction:\n",
    "            shipping_status = None \n",
    "        \n",
    "        created_at = order_date\n",
    "        modified_at = (datetime.strptime(created_at, \"%Y-%m-%d %H:%M:%S\") + timedelta(days=random.randint(1,30))).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        sales_data.append([sale_id, product_id, customer_id, branch_id, quantity, payment_method, order_date,\n",
    "                           order_status, payment_status, shipping_status, is_online_transaction, delivery_fee, is_free_delivery_fee, created_at, modified_at])\n",
    "        sale_id +=1\n",
    "\n",
    "df_sales = pd.DataFrame(sales_data, columns=[\"id\", \"product_id\", \"customer_id\", \"branch_id\", \"quantity\", \"payment_method\", \"order_date\",\n",
    "                                              \"order_status\", \"payment_status\", \"shipping_status\",\"is_online_transaction\", \"delivery_fee\", \"is_free_delivery_fee\", \"created_at\", \"modified_at\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_sales\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "product_id INT not null,\n",
    "customer_id int not null, \n",
    "branch_id int not null, \n",
    "quantity int not null, \n",
    "payment_method int, \n",
    "order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP, \n",
    "order_status int, \n",
    "payment_status int, \n",
    "shipping_status int, \n",
    "is_online_transaction varchar, \n",
    "delivery_fee int,\n",
    "is_free_delivery_fee varchar,\n",
    "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, \n",
    "modified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_sales.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_branch\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "name varchar not null, \n",
    "location varchar not null, \n",
    "address varchar, \n",
    "email varchar, \n",
    "phone varchar, \n",
    "created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP, \n",
    "modified_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_branch.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_product\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "product_name varchar,\n",
    "category varchar, \n",
    "sub_category varchar, \n",
    "price integer,\n",
    "profit int, \n",
    "stock int, \n",
    "created_time date, \n",
    "modified_time date null\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_product.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_shipping_status\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "name varchar,\n",
    "created_time date\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_shipping_status.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>created_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>processing</td>\n",
       "      <td>2025-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>failed</td>\n",
       "      <td>2025-02-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>paid</td>\n",
       "      <td>2025-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        name created_time\n",
       "0   1  processing   2025-02-20\n",
       "1   3      failed   2025-02-20\n",
       "2   2        paid   2025-02-20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_payment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_employee\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "branch_id int not null, \n",
    "name varchar,\n",
    "salary integer, \n",
    "active varchar, \n",
    "address varchar, \n",
    "phone varchar, \n",
    "email varchar, \n",
    "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_employee.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_schedule_employee\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "branch_id int not null, \n",
    "employee_id int not null, \n",
    "day varchar, \n",
    "date date,\n",
    "jam_shift varchar,\n",
    "created_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_schedule.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_promotions\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "event_name varchar not null, \n",
    "disc int not null, \n",
    "time date not null, \n",
    "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_promotions.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text \n",
    "\n",
    "# configurasi connection PostgreSQL \n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"tbl_customers\"\n",
    "\n",
    "# creatate connection to PostgreSQL\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_schema_query = f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA_NAME};\"\n",
    "cur.execute(create_schema_query)\n",
    "\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {SCHEMA_NAME}.{TABLE_NAME} (\n",
    "id INT PRIMARY KEY,\n",
    "name varchar not null, \n",
    "address varchar, \n",
    "phone varchar, \n",
    "email varchar, \n",
    "created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "modified_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "df_cust.to_sql(TABLE_NAME, engine, schema=SCHEMA_NAME, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent_kafka\n",
      "  Downloading confluent_kafka-2.8.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Downloading confluent_kafka-2.8.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.8/4.0 MB 907.1 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.0 MB 907.1 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.0 MB 907.1 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.8/4.0 MB 907.1 kB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 592.2 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 592.2 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.3/4.0 MB 578.4 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.3/4.0 MB 578.4 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.3/4.0 MB 578.4 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.6/4.0 MB 514.6 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.6/4.0 MB 514.6 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.6/4.0 MB 514.6 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.6/4.0 MB 514.6 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 484.0 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 2.1/4.0 MB 370.5 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 318.0 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 2.6/4.0 MB 280.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 2.6/4.0 MB 280.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 2.6/4.0 MB 280.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 2.6/4.0 MB 280.1 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 2.6/4.0 MB 280.1 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 2.9/4.0 MB 275.5 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 2.9/4.0 MB 275.5 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 2.9/4.0 MB 275.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 3.1/4.0 MB 283.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 3.1/4.0 MB 283.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 3.1/4.0 MB 283.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 3.1/4.0 MB 283.0 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 3.1/4.0 MB 283.0 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 278.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 278.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 278.1 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.4/4.0 MB 278.1 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 3.7/4.0 MB 278.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 3.7/4.0 MB 278.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 3.7/4.0 MB 278.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 3.7/4.0 MB 278.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 3.7/4.0 MB 278.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------  3.9/4.0 MB 278.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 277.0 kB/s eta 0:00:00\n",
      "Installing collected packages: confluent_kafka\n",
      "Successfully installed confluent_kafka-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dikirim ke Kafka: tbl_sales [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales [0]\n",
      "✅ 3 data berhasil dikirim ke Kafka!\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import time\n",
    "import uuid \n",
    "import random \n",
    "from datetime import datetime \n",
    "from faker import Faker\n",
    "from confluent_kafka import Producer\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "KAFKA_BROKER = \"localhost:9092\"\n",
    "TOPIC_NAME = \"tbl_sales_new\"\n",
    "\n",
    "\n",
    "producer_conf = {'bootstrap.servers': KAFKA_BROKER}\n",
    "producer = Producer(producer_conf)\n",
    "# Konfigurasi PostgreSQL\n",
    "\n",
    "POSTGRES_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"sales-project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\"\n",
    "}\n",
    "\n",
    "def get_list(column, tabel):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"select {column} from {tabel} order by {column}\")\n",
    "        products = [row[0] for row in cur.fetchall()]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return products\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil produk dari PostgreSQL: {e}\")\n",
    "        return []\n",
    "    \n",
    "def get_max_id():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"select coalesce(max(id), 0) from tbl_sales\")\n",
    "        max_id = cur.fetchone()[0]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return max_id\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil max transaction_id dari PostgreSQL: {e}\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "product_list = get_list('id', 'tbl_product')\n",
    "customer_list = get_list('id', 'tbl_customers')\n",
    "branch_list = get_list('id', 'tbl_branch')\n",
    "payment_method_list = get_list('id', 'tbl_payment_method')\n",
    "\n",
    "order_status_list = get_list('id', 'tbl_order_status')\n",
    "order_status_list_weights = [0.1, 0.9]\n",
    "\n",
    "payment_status_list = get_list('id', 'tbl_payment_status')\n",
    "payment_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "shipping_status_list = get_list('id', 'tbl_shipping_status')\n",
    "shipping_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "\n",
    "\n",
    "def generate_sales_data():\n",
    "    num_rows = random.randint(1,5)\n",
    "    sales_data = []\n",
    "    start_id = get_max_id()\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "\n",
    "        order_status =  random.choices(order_status_list, weights=order_status_list_weights, k=1)[0]\n",
    "        payment_status = None\n",
    "        shipping_status = None\n",
    "        is_online_transaction = random.choice([True, False])\n",
    "        delivery_fee = 0\n",
    "        is_free_delivery_fee = None \n",
    "\n",
    "        if is_online_transaction: \n",
    "            delivery_fee = random.randint(12000,50000)\n",
    "            is_free_delivery_fee = random.choice([True, False])\n",
    "\n",
    "\n",
    "        if order_status == 2:\n",
    "            payment_status = random.choices(payment_status_list, weights=payment_status_list_weights, k=1)[0]\n",
    "            if payment_status ==2:\n",
    "                shipping_status = random.choices(shipping_status_list, weights=shipping_status_list_weights, k=1)[0]\n",
    "        \n",
    "        if not is_online_transaction:\n",
    "            shipping_status = None\n",
    "        created_at = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "        sale = {\n",
    "            \"id\":start_id + i +1,\n",
    "            \"product_id\": random.choice(product_list),\n",
    "            \"customer_id\": random.choice(customer_list),\n",
    "            \"branch_id\": random.choice(branch_list),\n",
    "            \"quantity\": random.randint(1,5),\n",
    "            \"payment_method\": random.choice(payment_method_list),\n",
    "            \"order_date\": created_at,\n",
    "            \"order_status\": order_status,\n",
    "            \"payment_status\": payment_status,\n",
    "            \"shipping_status\": shipping_status,\n",
    "            \"is_online_transaction\": is_online_transaction,\n",
    "            \"delivery_fee\": delivery_fee,\n",
    "            \"is_free_delivery_fee\": is_free_delivery_fee,\n",
    "            \"created_at\":created_at,\n",
    "            \"modified_at\": created_at,\n",
    "        }\n",
    "        sales_data.append(sale)\n",
    "    return sales_data\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback untuk menangani hasil pengiriman Kafka\"\"\"\n",
    "    if err is not None:\n",
    "        print(f\"❌ Gagal mengirim pesan: {err}\")\n",
    "    else:\n",
    "        print(f\"✅ Data dikirim ke Kafka: {msg.topic()} [{msg.partition()}]\")\n",
    "\n",
    "while True:\n",
    "    sales_data = generate_sales_data()\n",
    "    for record in sales_data:\n",
    "        producer.produce(TOPIC_NAME, json.dumps(record).encode(\"utf-8\"), callback=delivery_report)\n",
    "    producer.flush()\n",
    "\n",
    "    print(f\"✅ {len(sales_data)} data berhasil dikirim ke Kafka!\")\n",
    "    time.sleep(60)  # Tunggu 1 menit sebelum mengirim data baru\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ 5 data berhasil dikirim ke Kafka!\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random \n",
    "import json \n",
    "import time\n",
    "import uuid \n",
    "import random \n",
    "from datetime import datetime \n",
    "from faker import Faker\n",
    "from confluent_kafka import Producer\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "KAFKA_BROKER = \"localhost:9092\"\n",
    "TOPIC_NAME = \"tbl_sales_schema_new\"\n",
    "\n",
    "\n",
    "producer_conf = {'bootstrap.servers': KAFKA_BROKER}\n",
    "producer = Producer(producer_conf)\n",
    "# Konfigurasi PostgreSQL\n",
    "\n",
    "POSTGRES_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"sales_project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\"\n",
    "}\n",
    "\n",
    "def get_list(column, tabel):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"select {column} from {tabel} order by {column}\")\n",
    "        products = [row[0] for row in cur.fetchall()]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return products\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil produk dari PostgreSQL: {e}\")\n",
    "        return []\n",
    "    \n",
    "def get_max_id():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"select coalesce(max(id), 0) from tbl_sales\")\n",
    "        max_id = cur.fetchone()[0]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return max_id\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil max transaction_id dari PostgreSQL: {e}\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "product_list = get_list('id', 'tbl_product')\n",
    "customer_list = get_list('id', 'tbl_customers')\n",
    "branch_list = get_list('id', 'tbl_branch')\n",
    "payment_method_list = get_list('id', 'tbl_payment_method')\n",
    "\n",
    "order_status_list = get_list('id', 'tbl_order_status')\n",
    "order_status_list_weights = [0.1, 0.9]\n",
    "\n",
    "payment_status_list = get_list('id', 'tbl_payment_status')\n",
    "payment_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "shipping_status_list = get_list('id', 'tbl_shipping_status')\n",
    "shipping_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "\n",
    "def generate_sales_data():\n",
    "    num_rows = random.randint(1,5)\n",
    "    sales_data = []\n",
    "    start_id = get_max_id()\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        id = start_id + i +1\n",
    "        product_id = random.choice(product_list)\n",
    "        customer_id = random.choice(customer_list)\n",
    "        branch_id = random.choice(branch_list)\n",
    "        quantity = random.randint(1,5)\n",
    "        payment_method = random.choice(payment_method_list)\n",
    "        order_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        order_status = random.choices(order_status_list, weights=order_status_list_weights, k=1)[0]\n",
    "        payment_status = None\n",
    "        shipping_status = None \n",
    "        is_online_transaction = random.choice([True, False])\n",
    "        delivery_fee = 0\n",
    "        is_free_delivery_fee =None\n",
    "\n",
    "        if is_online_transaction:\n",
    "            delivery_fee = random.randint(12000, 50000)\n",
    "            is_free_delivery_fee = random.choice([True, False])\n",
    "\n",
    "        if order_status ==2:\n",
    "            payment_status = random.choices(payment_status_list, weights=payment_status_list_weights, k=1)[0]\n",
    "            if payment_status ==2:\n",
    "                shipping_status = random.choices(shipping_status_list, weights=shipping_status_list_weights, k=1)[0]\n",
    "        \n",
    "\n",
    "        if not is_online_transaction:\n",
    "            shipping_status = None \n",
    "\n",
    "        payload = {\n",
    "            \"id\": id,\n",
    "            \"product_id\": product_id,\n",
    "            \"customer_id\":customer_id,\n",
    "            \"branch_id\":branch_id,\n",
    "            \"quantity\": quantity,\n",
    "            \"payment_method\":payment_method,\n",
    "            \"order_date\":order_date,\n",
    "            \"order_status\":order_status,\n",
    "            \"payment_status\":payment_status,\n",
    "            \"shipping_status\":shipping_status,\n",
    "            \"is_online_transaction\":is_online_transaction,\n",
    "            \"delivery_fee\": delivery_fee,\n",
    "            \"is_free_delivery_fee\": is_free_delivery_fee,\n",
    "            \"created_at\": order_date, \n",
    "            \"modified_at\": None\n",
    "        }\n",
    "\n",
    "        schema = {\n",
    "            \"schema\": {\n",
    "                \"fields\":[\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"product_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"customer_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"branch_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"quantity\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"payment_method\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"order_date\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"order_status\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"payment_status\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"shipping_status\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"is_online_transaction\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"delivery_fee\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"is_free_delivery_fee\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"created_at\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"modified_at\"},\n",
    "                ],\n",
    "                \"optional\": False,\n",
    "                \"name\": \"sales_schema\",\n",
    "                \"type\": \"struct\"\n",
    "            },\n",
    "            \"payload\": payload\n",
    "        }\n",
    "        sales_data.append(schema)\n",
    "    return sales_data\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback untuk menangani hasil pengiriman Kafka\"\"\"\n",
    "    if err is not None:\n",
    "        print(f\"❌ Gagal mengirim pesan: {err}\")\n",
    "    else:\n",
    "        print(f\"✅ Data dikirim ke Kafka: {msg.topic()} [{msg.partition()}]\")\n",
    "\n",
    "while True:\n",
    "    sales_data = generate_sales_data()\n",
    "    for record in sales_data:\n",
    "        producer.produce(TOPIC_NAME, json.dumps(record).encode(\"utf-8\"), callback=delivery_report)\n",
    "    producer.flush()\n",
    "\n",
    "    print(f\"✅ {len(sales_data)} data berhasil dikirim ke Kafka!\")\n",
    "    time.sleep(3600)  # Tunggu 1 menit sebelum mengirim data baru\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     while True:\n",
    "#         sales_data = generate_sales_data()\n",
    "#         for sale in sales_data:\n",
    "#             producer.send(TOPIC_NAME, value=sale)\n",
    "#             print(f\"✅ Data sent to Kafka: {json.dumps(sale, indent=2)}\")\n",
    "\n",
    "#         time.sleep(60)  # Generate data setiap 1 menit       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ 5 data berhasil dikirim ke Kafka!\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ 4 data berhasil dikirim ke Kafka!\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ Data dikirim ke Kafka: tbl_sales_schema_new [0]\n",
      "✅ 4 data berhasil dikirim ke Kafka!\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import random \n",
    "import time\n",
    "import uuid \n",
    "from datetime import datetime \n",
    "from faker import Faker\n",
    "from confluent_kafka import Producer\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "KAFKA_BROKER = \"localhost:9092\"\n",
    "TOPIC_NAME = \"tbl_sales_schema_new\"\n",
    "\n",
    "producer_conf = {'bootstrap.servers': KAFKA_BROKER}\n",
    "producer = Producer(producer_conf)\n",
    "\n",
    "# Konfigurasi PostgreSQL dengan port\n",
    "POSTGRES_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5444,  # Ganti dengan port yang sesuai\n",
    "    \"database\": \"sales_project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\"\n",
    "}\n",
    "\n",
    "def get_list(column, tabel):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT {column} FROM {tabel} ORDER BY {column}\")\n",
    "        data = [row[0] for row in cur.fetchall()]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil data dari PostgreSQL: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_max_id():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT COALESCE(MAX(id), 0) FROM tbl_sales\")\n",
    "        max_id = cur.fetchone()[0]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return max_id\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil max ID dari PostgreSQL: {e}\")\n",
    "        return 0\n",
    "\n",
    "product_list = get_list('id', 'tbl_product')\n",
    "customer_list = get_list('id', 'tbl_customers')\n",
    "branch_list = get_list('id', 'tbl_branch')\n",
    "payment_method_list = get_list('id', 'tbl_payment_method')\n",
    "order_status_list = get_list('id', 'tbl_order_status')\n",
    "order_status_list_weights = [0.1, 0.9]\n",
    "payment_status_list = get_list('id', 'tbl_payment_status')\n",
    "payment_status_list_weights = [0.05, 0.9, 0.05]\n",
    "shipping_status_list = get_list('id', 'tbl_shipping_status')\n",
    "shipping_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "def generate_sales_data():\n",
    "    num_rows = random.randint(1, 5)\n",
    "    sales_data = []\n",
    "    start_id = get_max_id()\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        id = start_id + i + 1\n",
    "        product_id = random.choice(product_list)\n",
    "        customer_id = random.choice(customer_list)\n",
    "        branch_id = random.choice(branch_list)\n",
    "        quantity = random.randint(1, 5)\n",
    "        payment_method = random.choice(payment_method_list)\n",
    "        order_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        order_status = random.choices(order_status_list, weights=order_status_list_weights, k=1)[0]\n",
    "        payment_status = None\n",
    "        shipping_status = None \n",
    "        is_online_transaction = random.choice([True, False])\n",
    "        delivery_fee = 0\n",
    "        is_free_delivery_fee = None\n",
    "\n",
    "        if is_online_transaction:\n",
    "            delivery_fee = random.randint(12000, 50000)\n",
    "            is_free_delivery_fee = random.choice([True, False])\n",
    "\n",
    "        if order_status == 2:\n",
    "            payment_status = random.choices(payment_status_list, weights=payment_status_list_weights, k=1)[0]\n",
    "            if payment_status == 2:\n",
    "                shipping_status = random.choices(shipping_status_list, weights=shipping_status_list_weights, k=1)[0]\n",
    "\n",
    "        if not is_online_transaction:\n",
    "            shipping_status = None \n",
    "\n",
    "        payload = {\n",
    "            \"id\": id,\n",
    "            \"product_id\": product_id,\n",
    "            \"customer_id\": customer_id,\n",
    "            \"branch_id\": branch_id,\n",
    "            \"quantity\": quantity,\n",
    "            \"payment_method\": payment_method,\n",
    "            \"order_date\": order_date,\n",
    "            \"order_status\": order_status,\n",
    "            \"payment_status\": payment_status,\n",
    "            \"shipping_status\": shipping_status,\n",
    "            \"is_online_transaction\": is_online_transaction,\n",
    "            \"delivery_fee\": delivery_fee,\n",
    "            \"is_free_delivery_fee\": is_free_delivery_fee,\n",
    "            \"created_at\": order_date, \n",
    "            \"modified_at\": None\n",
    "        }\n",
    "\n",
    "        schema = {\n",
    "            \"schema\": {\n",
    "                \"fields\": [\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"product_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"customer_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"branch_id\"},\n",
    "                    {\"type\": \"int32\", \"optional\": False, \"field\": \"quantity\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"payment_method\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"order_date\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"order_status\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"payment_status\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"shipping_status\"},\n",
    "                    {\"type\": \"boolean\", \"optional\": True, \"field\": \"is_online_transaction\"},\n",
    "                    {\"type\": \"int32\", \"optional\": True, \"field\": \"delivery_fee\"},\n",
    "                    {\"type\": \"boolean\", \"optional\": True, \"field\": \"is_free_delivery_fee\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"created_at\"},\n",
    "                    {\"type\": \"string\", \"optional\": True, \"field\": \"modified_at\"},\n",
    "                ],\n",
    "                \"optional\": False,\n",
    "                \"name\": \"sales_schema\",\n",
    "                \"type\": \"struct\"\n",
    "            },\n",
    "            \"payload\": payload\n",
    "        }\n",
    "        sales_data.append(schema)\n",
    "    return sales_data\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback untuk menangani hasil pengiriman Kafka\"\"\"\n",
    "    if err is not None:\n",
    "        print(f\"❌ Gagal mengirim pesan: {err}\")\n",
    "    else:\n",
    "        print(f\"✅ Data dikirim ke Kafka: {msg.topic()} [{msg.partition()}]\")\n",
    "\n",
    "while True:\n",
    "    sales_data = generate_sales_data()\n",
    "    for record in sales_data:\n",
    "        producer.produce(TOPIC_NAME, json.dumps(record).encode(\"utf-8\"), callback=delivery_report)\n",
    "    producer.flush()\n",
    "\n",
    "    print(f\"✅ {len(sales_data)} data berhasil dikirim ke Kafka!\")\n",
    "    time.sleep(3600)  # Tunggu 1 jam sebelum mengirim data baru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random \n",
    "import json \n",
    "import time\n",
    "import uuid \n",
    "import random \n",
    "from datetime import datetime \n",
    "from faker import Faker\n",
    "from confluent_kafka import Producer\n",
    "import psycopg2\n",
    "\n",
    "fake = Faker()\n",
    "KAFKA_BROKER = \"localhost:9092\"\n",
    "TOPIC_NAME = \"tbl_sales_schema_new2\"\n",
    "\n",
    "\n",
    "producer_conf = {'bootstrap.servers': KAFKA_BROKER}\n",
    "producer = Producer(producer_conf)\n",
    "# Konfigurasi PostgreSQL\n",
    "\n",
    "POSTGRES_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"sales-project\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\"\n",
    "}\n",
    "\n",
    "def get_list(column, tabel):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"select {column} from {tabel} order by {column}\")\n",
    "        products = [row[0] for row in cur.fetchall()]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return products\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil produk dari PostgreSQL: {e}\")\n",
    "        return []\n",
    "    \n",
    "def get_max_id():\n",
    "    try:\n",
    "        conn = psycopg2.connect(**POSTGRES_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"select coalesce(max(id), 0) from tbl_sales\")\n",
    "        max_id = cur.fetchone()[0]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        return max_id\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gagal mengambil max transaction_id dari PostgreSQL: {e}\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "product_list = get_list('id', 'tbl_product')\n",
    "customer_list = get_list('id', 'tbl_customers')\n",
    "branch_list = get_list('id', 'tbl_branch')\n",
    "payment_method_list = get_list('id', 'tbl_payment_method')\n",
    "\n",
    "order_status_list = get_list('id', 'tbl_order_status')\n",
    "order_status_list_weights = [0.1, 0.9]\n",
    "\n",
    "payment_status_list = get_list('id', 'tbl_payment_status')\n",
    "payment_status_list_weights = [0.05, 0.9, 0.05]\n",
    "\n",
    "shipping_status_list = get_list('id', 'tbl_shipping_status')\n",
    "shipping_status_list_weights = [0.05, 0.9, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_method_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data done insert ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"sum_transactions\"\n",
    "\n",
    "# create connection to database \n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "query_employee = f\"SELECT id, branch_id, name, salary  from {SCHEMA_NAME}.tbl_employee where active = 'true';\"\n",
    "df_employee =pd.read_sql(query_employee, engine)\n",
    "\n",
    "# create data transaksi gaji for each month (Januari - Desember)\n",
    "transactions = []\n",
    "current_year = datetime.today().year\n",
    "\n",
    "for _, row in df_employee.iterrows():\n",
    "    for month in range(1,13):\n",
    "        transactions.append({\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"branch_id\"],\n",
    "            \"employee_id\": row[\"id\"],\n",
    "            \"description\": f\"Monthly Salary {row[\"name\"]}\",\n",
    "            \"date\": datetime(current_year, month, 1).strftime(\"%Y-%m-%d\"),\n",
    "            \"amount\": row[\"salary\"]\n",
    "        })\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "df_transactions.to_sql(TABLE_NAME,engine, schema= SCHEMA_NAME, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Data done insert ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import random \n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "start_date = datetime(2025, 1, 2)\n",
    "end_date = datetime(2025,12,31)\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "TABLE_NAME  = \"sum_transactions\"\n",
    "\n",
    "# create connection to database \n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "query_branch = f\"select * from {SCHEMA_NAME}.tbl_branch;\"\n",
    "df_branch = pd.read_sql(query_branch, engine)\n",
    "\n",
    "\n",
    "transactions =  []\n",
    "current_year = datetime.today().year\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    for _, row in df_branch.iterrows():\n",
    "        amount = random.randint(200000, 400000)\n",
    "        transactions.append({\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"id\"],\n",
    "            \"description\": f\"Pengeluaran Operasional Cabang {row[\"name\"]} sebesar Rp. {amount}\",\n",
    "            \"date\": current_date,\n",
    "            \"sales_id\": None,\n",
    "            \"employee_id\": None,\n",
    "            \"amount\": amount\n",
    "        })\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "\n",
    "df_transactions.to_sql(\"sum_transactions\", engine, schema=SCHEMA_NAME,if_exists=\"append\", index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sales_id</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Pengeluaran Operasional Cabang Taylor, Jimenez...</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>391325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>Pengeluaran Operasional Cabang Johnson-Brown s...</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>390755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>Pengeluaran Operasional Cabang Brown and Sons ...</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>225329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>Pengeluaran Operasional Cabang Carter-Powell s...</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>201253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>Pengeluaran Operasional Cabang Hensley, Davenp...</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>None</td>\n",
       "      <td>363096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18195</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>46</td>\n",
       "      <td>Pengeluaran Operasional Cabang Rivera Inc sebe...</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>315445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18196</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>47</td>\n",
       "      <td>Pengeluaran Operasional Cabang Gibson, Jones a...</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>210824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18197</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>48</td>\n",
       "      <td>Pengeluaran Operasional Cabang Blanchard-Brown...</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>346401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18198</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>49</td>\n",
       "      <td>Pengeluaran Operasional Cabang Griffin, Campbe...</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>292865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18199</th>\n",
       "      <td>outcome</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>Pengeluaran Operasional Cabang Avery, Becker a...</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>312330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type sales_id  branch_id  \\\n",
       "0      outcome     None          1   \n",
       "1      outcome     None          2   \n",
       "2      outcome     None          3   \n",
       "3      outcome     None          4   \n",
       "4      outcome     None          5   \n",
       "...        ...      ...        ...   \n",
       "18195  outcome     None         46   \n",
       "18196  outcome     None         47   \n",
       "18197  outcome     None         48   \n",
       "18198  outcome     None         49   \n",
       "18199  outcome     None         50   \n",
       "\n",
       "                                             description       date  \\\n",
       "0      Pengeluaran Operasional Cabang Taylor, Jimenez... 2025-01-02   \n",
       "1      Pengeluaran Operasional Cabang Johnson-Brown s... 2025-01-02   \n",
       "2      Pengeluaran Operasional Cabang Brown and Sons ... 2025-01-02   \n",
       "3      Pengeluaran Operasional Cabang Carter-Powell s... 2025-01-02   \n",
       "4      Pengeluaran Operasional Cabang Hensley, Davenp... 2025-01-02   \n",
       "...                                                  ...        ...   \n",
       "18195  Pengeluaran Operasional Cabang Rivera Inc sebe... 2025-12-31   \n",
       "18196  Pengeluaran Operasional Cabang Gibson, Jones a... 2025-12-31   \n",
       "18197  Pengeluaran Operasional Cabang Blanchard-Brown... 2025-12-31   \n",
       "18198  Pengeluaran Operasional Cabang Griffin, Campbe... 2025-12-31   \n",
       "18199  Pengeluaran Operasional Cabang Avery, Becker a... 2025-12-31   \n",
       "\n",
       "      employee_id  amount  \n",
       "0            None  391325  \n",
       "1            None  390755  \n",
       "2            None  225329  \n",
       "3            None  201253  \n",
       "4            None  363096  \n",
       "...           ...     ...  \n",
       "18195        None  315445  \n",
       "18196        None  210824  \n",
       "18197        None  346401  \n",
       "18198        None  292865  \n",
       "18199        None  312330  \n",
       "\n",
       "[18200 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "query_branch = f\"select * from {SCHEMA_NAME}.tbl_branch;\"\n",
    "df_branch = pd.read_sql(query_branch, engine)\n",
    "\n",
    "transactions = []\n",
    "current_year = datetime.today().year\n",
    "\n",
    "for _, row in df_branch.iterrows():\n",
    "    for month in range(1,13):\n",
    "        amount = random.randint(1000000, 2000000)\n",
    "        transactions.append({\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"id\"],\n",
    "            \"employee_id\": None, \n",
    "            \"description\": f\"Pembayaran Listrik dan Air Cabang {row[\"name\"]} sebesar Rp. {amount}\",\n",
    "            \"date\": datetime(current_year, month, 1).strftime(\"%Y-%m-%d\"),  # Setiap tanggal 1 bulan tersebut\n",
    "            \"amount\": amount\n",
    "        })\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "df_transactions.to_sql(\"sum_transactions\", engine, schema=SCHEMA_NAME,if_exists=\"append\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "query_branch = f\"select * from {SCHEMA_NAME}.tbl_branch;\"\n",
    "df_branch = pd.read_sql(query_branch, engine)\n",
    "\n",
    "transactions = []\n",
    "current_year = datetime.today().year\n",
    "\n",
    "for _, row in df_branch.iterrows():\n",
    "    for month in range(1,13):\n",
    "        amount = random.randint(1000000, 2000000)\n",
    "        transactions.append({\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"id\"],\n",
    "            \"employee_id\": None, \n",
    "            \"description\": f\"Pengeluaran Teknologi & IT {row[\"name\"]} sebesar Rp. {amount}\",\n",
    "            \"date\": datetime(current_year, month, 1).strftime(\"%Y-%m-%d\"),  # Setiap tanggal 1 bulan tersebut\n",
    "            \"amount\": amount\n",
    "        })\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "df_transactions.to_sql(\"sum_transactions\", engine, schema=SCHEMA_NAME,if_exists=\"append\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"postgres\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"sales-project\"\n",
    "SCHEMA_NAME = \"public\"\n",
    "\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "query_branch = f\"select * from {SCHEMA_NAME}.tbl_branch;\"\n",
    "df_branch = pd.read_sql(query_branch, engine)\n",
    "\n",
    "transactions = []\n",
    "current_year = datetime.today().year\n",
    "\n",
    "def random_date(start_date, end_date):\n",
    "    \"\"\"Menghasilkan tanggal acak antara start_date dan end_date\"\"\"\n",
    "    delta = end_date - start_date\n",
    "    random_days = random.randint(0, delta.days)\n",
    "    return start_date + timedelta(days=random_days)\n",
    "\n",
    "start = datetime(2025, 1, 1)\n",
    "end = datetime(2025, 12, 31)\n",
    "\n",
    "for _, row in df_branch.iterrows():\n",
    "    for month in range(1,4):\n",
    "        amount = random.randint(3000000, 7000000)\n",
    "        transactions.append({\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"id\"],\n",
    "            \"employee_id\": None, \n",
    "            \"description\": f\"Pengeluaran Pemeliharaan Cabang {row[\"name\"]} sebesar Rp. {amount}\",\n",
    "            \"date\": random_date(start, end),\n",
    "            \"amount\": amount\n",
    "        })\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions)\n",
    "\n",
    "df_transactions.to_sql(\"sum_transactions\", engine, schema=SCHEMA_NAME,if_exists=\"append\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_status</th>\n",
       "      <th>payment_status</th>\n",
       "      <th>shipping_status</th>\n",
       "      <th>is_online_transaction</th>\n",
       "      <th>delivery_fee</th>\n",
       "      <th>is_free_delivery_fee</th>\n",
       "      <th>created_at</th>\n",
       "      <th>modified_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-01-22 08:03:49</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>45099</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-01-22 08:03:49</td>\n",
       "      <td>2025-02-20 08:03:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-01-12 15:01:16</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36488</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-12 15:01:16</td>\n",
       "      <td>2025-02-07 15:01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-01-03 14:36:33</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>37593</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-01-03 14:36:33</td>\n",
       "      <td>2025-01-04 14:36:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-01-13 07:27:49</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>28176</td>\n",
       "      <td>True</td>\n",
       "      <td>2025-01-13 07:27:49</td>\n",
       "      <td>2025-02-04 07:27:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-01-15 07:36:29</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-01-15 07:36:29</td>\n",
       "      <td>2025-02-05 07:36:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>7556</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-12-06 14:47:27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-12-06 14:47:27</td>\n",
       "      <td>2025-12-26 14:47:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7556</th>\n",
       "      <td>7557</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-12-18 12:14:08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>13551</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-18 12:14:08</td>\n",
       "      <td>2025-12-23 12:14:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>7558</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-12-20 15:13:55</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>49950</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-20 15:13:55</td>\n",
       "      <td>2026-01-19 15:13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>7559</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-12-25 11:19:10</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-12-25 11:19:10</td>\n",
       "      <td>2025-12-27 11:19:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7559</th>\n",
       "      <td>7560</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-13 10:06:49</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26533</td>\n",
       "      <td>False</td>\n",
       "      <td>2025-12-13 10:06:49</td>\n",
       "      <td>2025-12-24 10:06:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7560 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  product_id  ...           created_at          modified_at\n",
       "0        1           7  ...  2025-01-22 08:03:49  2025-02-20 08:03:49\n",
       "1        2           4  ...  2025-01-12 15:01:16  2025-02-07 15:01:16\n",
       "2        3           8  ...  2025-01-03 14:36:33  2025-01-04 14:36:33\n",
       "3        4           3  ...  2025-01-13 07:27:49  2025-02-04 07:27:49\n",
       "4        5           3  ...  2025-01-15 07:36:29  2025-02-05 07:36:29\n",
       "...    ...         ...  ...                  ...                  ...\n",
       "7555  7556          10  ...  2025-12-06 14:47:27  2025-12-26 14:47:27\n",
       "7556  7557           9  ...  2025-12-18 12:14:08  2025-12-23 12:14:08\n",
       "7557  7558          13  ...  2025-12-20 15:13:55  2026-01-19 15:13:55\n",
       "7558  7559           3  ...  2025-12-25 11:19:10  2025-12-27 11:19:10\n",
       "7559  7560           3  ...  2025-12-13 10:06:49  2025-12-24 10:06:49\n",
       "\n",
       "[7560 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import random\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Database Configuration\n",
    "DB_CONFIG = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"dbname\": \"sales-project\",\n",
    "    \"schema\": \"public\",\n",
    "    \"table\": \"sum_transactions\"\n",
    "}\n",
    "\n",
    "def create_db_engine(config):\n",
    "    return create_engine(f\"postgresql+psycopg2://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['dbname']}\")\n",
    "\n",
    "def fetch_data(engine, query):\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "def insert_transactions(engine, transactions_df, config):\n",
    "    transactions_df.to_sql(config[\"table\"], engine, schema=config[\"schema\"], if_exists=\"append\", index=False)\n",
    "\n",
    "def generate_salary_transactions(engine, config):\n",
    "    query = f\"\"\"\n",
    "        SELECT id, branch_id, name, salary \n",
    "        FROM {config['schema']}.tbl_employee \n",
    "        WHERE active = 'true';\n",
    "    \"\"\"\n",
    "    df_employee = fetch_data(engine, query)\n",
    "    current_year = datetime.today().year\n",
    "    \n",
    "    transactions = [\n",
    "        {\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"branch_id\"],\n",
    "            \"employee_id\": row[\"id\"],\n",
    "            \"description\": f\"Monthly Salary {row['name']}\",\n",
    "            \"date\": datetime(current_year, month, 1).strftime(\"%Y-%m-%d\"),\n",
    "            \"amount\": row[\"salary\"]\n",
    "        }\n",
    "        for _, row in df_employee.iterrows()\n",
    "        for month in range(1, 13)\n",
    "    ]\n",
    "    insert_transactions(engine, pd.DataFrame(transactions), config)\n",
    "    print(\"Salary transactions inserted.\")\n",
    "\n",
    "def generate_operational_expenses(engine, config, start_date, end_date):\n",
    "    query = f\"SELECT id, name FROM {config['schema']}.tbl_branch;\"\n",
    "    df_branch = fetch_data(engine, query)\n",
    "    current_date = start_date\n",
    "    transactions = []\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        transactions.extend([\n",
    "            {\n",
    "                \"type\": \"outcome\",\n",
    "                \"sales_id\": None,\n",
    "                \"branch_id\": row[\"id\"],\n",
    "                \"employee_id\": None,\n",
    "                \"description\": f\"Pengeluaran Operasional Cabang {row['name']}\",\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"amount\": random.randint(200000, 400000)\n",
    "            }\n",
    "            for _, row in df_branch.iterrows()\n",
    "        ])\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    insert_transactions(engine, pd.DataFrame(transactions), config)\n",
    "    print(\"Operational expenses transactions inserted.\")\n",
    "\n",
    "def generate_utility_expenses(engine, config):\n",
    "    query = f\"SELECT id, name FROM {config['schema']}.tbl_branch;\"\n",
    "    df_branch = fetch_data(engine, query)\n",
    "    current_year = datetime.today().year\n",
    "    \n",
    "    transactions = [\n",
    "        {\n",
    "            \"type\": \"outcome\",\n",
    "            \"sales_id\": None,\n",
    "            \"branch_id\": row[\"id\"],\n",
    "            \"employee_id\": None,\n",
    "            \"description\": f\"Pembayaran Listrik dan Air Cabang {row['name']}\",\n",
    "            \"date\": datetime(current_year, month, 1).strftime(\"%Y-%m-%d\"),\n",
    "            \"amount\": random.randint(1000000, 2000000)\n",
    "        }\n",
    "        for _, row in df_branch.iterrows()\n",
    "        for month in range(1, 13)\n",
    "    ]\n",
    "    insert_transactions(engine, pd.DataFrame(transactions), config)\n",
    "    print(\"Utility expenses transactions inserted.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_db_engine(DB_CONFIG)\n",
    "    generate_salary_transactions(engine, DB_CONFIG)\n",
    "    generate_operational_expenses(engine, DB_CONFIG, datetime(2025, 1, 2), datetime(2025, 12, 31))\n",
    "    generate_utility_expenses(engine, DB_CONFIG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
